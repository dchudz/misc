#I should switch it so the vector of ys, mus, doesn't include 0

library(rstan)
library(ggplot2)
library(plyr)
setwd(Sys.getenv("GITHUB_PATH"))

# This is my model of how the data is generated. 
# The y's are normally distributed around the mu's, with (for convenience at this point) known variance.
# The variance for y's depends on how many points are in our discretization
#     (variance of mean-aggregated y's would scale as 1/N)
# Assuming mu's are generated by adding an appropriate chi-squared random variable to previous mu
generate_data <- function(k_0, s, N, sigma_0_sq) {
  mu <- rep(NA,N+1)
  mu[1] = 0
  for (i in 2:(N+1)) {
    mu[i] = mu[i-1] + s*rchisq(1, k_0/N)
  }
  y <- mu + rnorm(N+1, sd=sqrt(sigma_0_sq*N))
  y[1] <- 0
  t <- seq(0,1,1/N)
  data.frame(t=t, mu=mu, y=y)
}

k_0 = 20
s = 3
N = 50
sigma_0_sq = 1
set.seed(38836)
fake_data <- generate_data(k_0, s, N, sigma_0_sq)
N2 = 10

#times for aggregated fake data need to be shifted left so they're at the middle of the aggregated range
fake_data$t_aggregate = ceiling((fake_data$t)*N2)/N2 - 1/(2*N2)
fake_data_aggregate <- ddply(subset(fake_data, t_aggregate > 0), 
                             "t_aggregate", summarize, y_aggregate=mean(y))
fake_data_aggregate

#Here's our fake data and aggregated fake data
p1 <- ggplot() + 
  geom_line(data=fake_data, mapping=aes(x=t,y=mu, color="mu")) + 
  geom_point(data=fake_data, mapping=aes(x=t,y=y,color="y")) +
  geom_point(data=fake_data_aggregate, 
                         mapping=aes(x=t_aggregate,y=y_aggregate, color="y aggregated"),
                         size=5, alpha=.5) +
  scale_color_discrete("")
p1

increasing_model_dat <- list(k_0 = k_0, s=s, N=N, sigma_0_sq=sigma_0_sq, y=y <- fake_data$y)
fit1 <- stan("./misc/stan models/increasing_function_with_chi_square_jumps.stan", 
             data = increasing_model_dat, iter = 10000, chains = 4)
print(fit1)
#didn't converge. rerun with more iterations!
fit2 <- stan(fit= fit1, data = increasing_model_dat, iter = 100000, chains = 4)
print(fit2)
mu_means <- get_posterior_mean(fit2,pars="mu")[,5]
mu_means
p2 <- p1 + geom_line(aes(x=seq(0,1,1/N),y=mu_means, color="fitted mu"))
p2


# only changing y's and N
# (it's important that we can change the scale of discretization and keep the other parameters the same)
increasing_model_dat_aggregated <- list(k_0 = k_0, s=s, N=N2, sigma_0_sq=sigma_0_sq, 
                                        y=c(0,fake_data_aggregate$y))

fit1_aggregated <- stan(fit= fit1, data = increasing_model_dat_aggregated, iter = 10000, chains = 4)
print(fit1_aggregated)

mu_means_aggregated <- get_posterior_mean(fit1_aggregated,pars="mu")[,5]
p3 <- p2 + geom_line(aes(x=fake_data_aggregate$t,y=mu_means_aggregated[2:(N2+1)], color="fitted mu on aggregated ys"))
p3 + ggtitle("the data, the true mu's, and the posterior means for each model")

# this looks great! now I should plot some samples from each version (aggregated and not)
# the posterior means are a lot "smoother" than the truth -- I think that comes from the fact that 
# they're means rather than anything that should worry us
# We can look at some sammple paths to make sure we're comfortable

get_df_for_sample_aggregated <- function(num) {
  data.frame(
    mu = mu_aggregated_samples[num,2:(N2+1)],
    sample_num = num,
    t = fake_data_aggregate$t,
    model = "aggregated"
  ) 
}

get_df_for_sample <- function(num) {
  data.frame(
    mu = mu_samples[num,1:(N+1)],
    sample_num = num,
    t = fake_data$t,
    model = "unaggregated"
  ) 
}

mu_samples = extract(fit2,pars="mu")$mu
num_samples_to_show = 10
sample_nums = sample.int(nrow(mu_samples),num_samples_to_show)

mu_aggregated_samples = extract(fit1_aggregated,pars="mu")$mu
num_aggregated_samples_to_show = 10
sample_nums_aggregate = sample.int(nrow(mu_aggregated_samples),num_aggregated_samples_to_show)


sampleDF <- rbind(
  adply(sample_nums_aggregate, 1, get_df_for_sample_aggregated),
  adply(sample_nums, 1, get_df_for_sample)
)
sampleDF
ggplot(data=sampleDF) + 
  geom_line(mapping=aes(x=t, y=mu, group=sample_num,color=model)) +
  ggtitle("ten random samples from each model (aggregated and unaggregated) posterior")



## right now I'm assuming these are all known:
##    hyperparameters: k_0, s
##    variance for y's: sigma_0_sq
## next step would be including these as modeled parameters with a prior instead of treating them as known